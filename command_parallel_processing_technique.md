# 명령어 병렬 처리 기법

## 명령어 파이프라인
명령어가 처리되는 과정을 비슷한 시간 단위로 쪼개면 다음과 같은 4구간으로 설정될 수 있다.
- 1. 명령어 인출(Fetch)
- 2. 명령어 해석(Decode)
- 3. 명령어 실행(Execute)
- 4. 필요시 결과 저장(Write)

우선은 코어 한개 기준으로, CPU는 GPU와 달리 동시에 같은 작업을 처리하는 것은 불가능하고 매우 빠르게 직렬적으로 처리한다는 일반적인 관점이 존재한다.

명령어 파이프라인은 CPU가 동시에 명령어를 처리하는 기술이다.

명령어가 처리되는 4가지 과정, 즉 각각의 과정은 동시에 진행될 수 없다. 또, 명령어의 처리는 4가지 과정이 모두 완료되어야 처리가 되었다고 판단한다.

그렇다는 것은 4가지 과정을 과정1, 과정2, 과정3, 과정4로 나누었을때 과정1이 동시에 두 개 처리될 수는 없지만 과정1과 과정2는 동시에 처리될 수 있는 것이다.

명령어1이 `과정1 : 명령어 인출`의 처리가 끝나자마자 명령어2의 `과정1 : 명령어 인출`을 수행한다. 명령어2의 과정1이 수행되는 동안 명령어1은 `과정2`가 수행된다. 서로의 과정은 다르지만 CPU는 두 명령어를 동시에 처리하고 있다.

이렇게 쪼갠 과정에만 겹치지 않도록 명령어를 여러개 처리하는 기법을 `명령어 파이프라이닝`이라고 한다.

아래의 표를 참고하여 더욱 직관적으로 이해해보자.

| 클럭 싸이클 | 명령어1    | 명령어2    | 명령어3    |
| ------ | ------- | ------- | ------- |
| T1     | Fetch   |         |         |
| T2     | Decode  | Fetch   |         |
| T3     | Execute | Decode  | Fetch   |
| T4     | Write   | Execute | Decode  |
| T5     |         | Write   | Execute |
| T6     |         |         | Write   |

### 하나의 클럭 싸이클에 대해 여러개의 작업 수행이 가능한건가?

그렇다! 명령어 파이프라이닝 구조에서는 가능하다.

왜냐하면 명령어 파이프라인의 각 단계는 "최대한" 서로 다른 전용 하드웨어 유닛을 사용하기 때문이다.
(그렇지 않아 서로 다른 명령어가 각 처리 과정에서 같은 유닛을 점유하려고 하는 상황을 "구조 위험"이라고 한다.)

예를 들어, 인출(Fetch) 단계는 프로그램 카운터(PC), 명령어 캐시, 버스를 사용하고,

실행(Execute) 단계는 ALU(산술 논리 연산 유닛) 를 사용한다.

이처럼 각 단계가 사용하는 자원이 겹치지 않기 때문에,
같은 클럭 싸이클 내에서도 각 명령어가 다른 단계를 동시에 처리할 수 있다.

즉, CPU는 파이프라인을 통해 모든 유닛을 가능한 한 쉬지 않고 활용하여
명령어 처리 효율을 극대화하는 것이다.

## 파이프라인 리스크
파이프라인 리스크는 명령어 파이프라인이 파이프라인이 의도한 성능 향상에 실패하는 상황을 말한다.

### 데이터 리스크
명령어 간의 의존성에 의해 야기되는 위험이다.

위의 파이프라인이 적용된 예시 표를 다시 참고해보자.

만약 명령어2가 명령어1이 완료되고 Write된 데이터를 Fetch해서 사용해야한다면 명령어1과 2는 파이프라이닝이 적용될 수 없을 것이다.

### 제어 리스크
1번 명령어를 수행하다보니 `3과정 : 명령어 실행`에서 점프가 일어나야한다고 생각해보자.

1번 명령어의 3과정이 진행되는 시점에는 2번 명령어의 2과정, 3번 명령어의 1과정이 실행중일 것이다.

즉 이 상황에서는 2,3 명령어가 일부 처리되는 과정이 갑자기 `쓰레기`가 된다.

안하느니만 못한 상황이 펼쳐지는 것이다. 이러한 위험을 제어 리스크라고 한다.

### 구조 위험
서로 다른 명령어가 같은 CPU 부품(레지스터, ALU)을 사용하려 할 때 발생하는 위험이다.

## 슈퍼 스칼라 구조
| 클럭 싸이클 | 명령어1         | 명령어2         | 명령어3         | 명령어4         |
| ------ | ------------ | ------------ | ------------ | ------------ |
| T1     | Fetch (P1)   | Fetch (P2)   |              |              |
| T2     | Decode (P1)  | Decode (P2)  | Fetch (P1)   | Fetch (P2)   |
| T3     | Execute (P1) | Execute (P2) | Decode (P1)  | Decode (P2)  |
| T4     | Write (P1)   | Write (P2)   | Execute (P1) | Execute (P2) |
| T5     |              |              | Write (P1)   | Write (P2)   |

하나의 클럭 싸이클에 대해 동시에 몇개의 명령어를 처리할 수 있느냐에 대한 개념이며 위는 동시에 두 개의 명령어를 처리하는 기준으로 작성된 예시 표이다.

우리가 위에서 파악한 파이프라인 리스크와 더불어 파이프라인 동기화 같은 문제 때문에 실제로 여러 코어에 여러 파이프라인을 두어 처리한다 하더라도 파이프라인 수에 비례해서 성능이 증가하지는 않는다. 파이프라인 개수가 늘어난다면 그에 따라 파이프라인 위험도도 증가하기 때문이다.

![image](https://github.com/user-attachments/assets/2c65ef5c-7550-4d08-b354-fa33a734e483)

위는 실제 CPU를 Cinebench 프로그램으로 하여금 성능 점수를 뽑아낸 자료이다.

싱글점수(1개 쓰레드 성능)가 2000점대를 보이고 있다. 16 쓰레드이므로 쓰레드 수에 비례한 성능을 보이려면 2000 * 16 즉 32000점을 나타내어야 하지만 멀티점수(모든 쓰레드 활용)의 경우 23000점을 나타내고 있다.

슈퍼 스칼라 구조는 스레드를 세부설명한 것이 아니다. 만약 8코어 16스레드 4-way 슈퍼 스칼라라면 하나의 코어에 2개의 하드웨어 쓰레드가 존재하며 4-way 슈퍼 스칼라이므로 하나의 코어는 두 개의 쓰레드를 가지며 두 개의 쓰레드는 각각 동시에 4개의 명령어를 실행 가능한 파이프라인을 가지는 것이다.

그렇다면 **코어당 2스레드, 4-way 슈퍼스칼라 구조는 하나의 코어에서 동시에 8개의 명령어를 처리할 수 있느냐?**라는 질문에는,
꼭 그렇지는 않다고 답해야 한다.

왜냐하면, **클럭당 발행 가능한 명령어 수는 이론적인 최대치(= 2×4 = 8)**에 도달하지 못하는 경우가 많기 때문이다.
그 이유는 데이터 의존성, 메모리 지연, 분기 예측 실패 등으로 인해 명령어 공급이 부족하거나,
두 스레드가 모두 동시에 충분한 명령어를 발행하지 못하는 경우가 발생하기 때문이다.

그럼에도 CPU가 슈퍼스칼라 issue 폭을 여유롭게 설계하는 이유는,
한 스레드가 자원을 충분히 활용하지 못할 때 다른 스레드가 남는 자원을 가져가 활용함으로써
전체 파이프라인 활용률을 높이기 위함이다.

하나의 코어에 대해 코어보다 많은 쓰레드가 존재하는 것을 SMT라고 하며 그것에 더해 하나의 쓰레드가 동시에 여러 명령어를 실행할 수 있는 슈퍼스칼라 구조를 이용한다면 SMT + 슈퍼스칼라 구조라고 봐야한다.


```
[ 소프트웨어 프로그램 ]
        │
        ▼
┌────────────────────────────────────┐
│        프로그램 스레드 2개              │
│  ┌────────────┐   ┌────────────┐   │
│  │ Thread 1   │   │ Thread 2   │   │
│  │ ─ instr A  │   │ ─ instr D  │   │
│  │ ─ instr B  │   │ ─ instr E  │   │
│  │ ─ instr C  │   │ ─ instr F  │   │
│  └────────────┘   └────────────┘   │
└────────────┬──────────────────────┘
             ▼
        [ 하드웨어 코어 1 ]
             │ SMT (2-way)
      ┌─────────────────────────────┐
      │       HW 스레드 1             │
      │  ↳ 명령어 A, B, C 공급         │
      │                             │
      │       HW 스레드 2             │
      │  ↳ 명령어 D, E, F 공급         │
      └────────────┬────────────────┘
                   ▼
         [ 슈퍼스칼라 실행 유닛 ]
   ┌────────────────────────────────┐
   │ 클럭당 최대 6개 명령어 실행 가능       │  ← 예: 6-way issue
   │ ─ instr A (ALU)                 │
   │ ─ instr D (Load)                │
   │ ─ instr B (FPU)                 │
   │ ─ instr E (Branch)              │
   │ ─ instr C (ALU)                 │
   │ ─ instr F (Store)               │
   └────────────────────────────────┘
```

## 비순차적 명령어 처리
`비순차적 명령어 처리`란 명령어들 간의 **`합법적 새치기`**이다.

비순차적 명령어 처리가 없다면 CPU는 명령어를 **순차적으로만** 처리하게 된다.

이런 상황에서는 위에서 알아보았듯 파이프라인 리스크 중 데이터 리스크가 발생할 수 있다.

다른 명령어에 종속적인 명령어가 있다면 그것을 순차를 무시하고 뒤로 빼버린다면 파이프라인 위험을 피해 

의도한 파이프라인 성능을 기대할 수 있을 것이다.

`순서를 바꾸어도 전체 프로그램 실행 결과에 영향을 주지 않을 때`만 이 기법이 적용될 수 있다.

> `순서를 바꾸어도 전체 프로그램 실행 결과에 영향을 주지 않을 때`를 판단하는 것또한 대단한 비용이지 않나?
> 그렇긴 하고 하드웨어 논리 회로 수준으로 구현이 어렵고 판단에 사용되는 CPU 작업량도 존재하겠지만 
> 그것보다는 얻는 이득(파이프라이닝 정상 수행)이 훨씬 크기때문에 현대의 CPU는 이러한 구현을 대부분 적용한다.

---

## 병렬 처리 기법의 종류

컴퓨터 시스템은 성능 향상을 위해 다양한 병렬 처리 기법을 활용한다. 이 기법들은 주로 명령어 수준 병렬성(ILP), 스레드 수준 병렬성(TLP), 그리고 데이터 수준 병렬성(DLP)으로 나눌 수 있다.

### 1. 명령어 수준 병렬성 (ILP: Instruction-Level Parallelism)

*   **정의**: 하나의 스레드 내에서 독립적인 명령어들을 동시에 실행하는 기술이다.
*   **목적**: 단일 프로그램의 실행 속도를 높이는 것이 목적이다.
*   **활용 예시**:
    *   **파이프라이닝(Pipelining)**: 명령어를 인출, 해석, 실행, 저장 등 여러 단계로 나누어 동시에 다른 명령어들을 각기 다른 단계에서 처리하는 기법이다.
    *   **슈퍼스칼라(Superscalar)**: CPU 내부에 여러 개의 실행 유닛을 두어, 한 클럭 사이클에 여러 개의 독립적인 명령어를 동시에 실행하는 기법이다.
    *   **비순차적 명령어 처리(Out-of-Order Execution)**: 명령어들 간의 의존성을 분석하여 종속성이 없는 명령어를 먼저 실행함으로써, 파이프라인의 멈춤 현상(Stall)을 줄이고 효율을 높이는 기법이다.
*   **적용 예시**: 하나의 복잡한 수치 연산을 빠르게 수행하는 데 기본적인 밑바탕이 되는 기술이다.

### 2. 스레드 수준 병렬성 (TLP: Thread-Level Parallelism)

*   **정의**: 여러 개의 독립적인 스레드(작업 단위)를 동시에 실행하는 기술이다.
*   **목적**: 전체 시스템의 처리량(Throughput)을 높이는 것이 목적이다.
*   **활용 예시**:
    *   **멀티코어 프로세서(Multi-core Processor)**: CPU 내부에 여러 개의 독립적인 코어를 두어 각 코어가 별도의 스레드를 동시에 실행한다.
    *   **하이퍼스레딩(Hyper-Threading) 또는 SMT(Simultaneous Multi-threading)**: 하나의 물리 코어가 마치 여러 개의 논리 코어처럼 동작하여, 각 논리 코어(하드웨어 스레드)가 별도의 스레드를 동시에 실행하도록 하는 기법이다. 이는 물리 코어의 유휴 자원 활용도를 높인다.
*   **적용 예시**:
    *   **대용량 이미지 파일 100개의 색상 보정 작업**: 각 이미지 파일은 독립적인 작업 단위이므로, 여러 CPU 코어/스레드가 각각 다른 이미지를 동시에 처리한다.
    *   **복잡한 데이터베이스 쿼리 실행**: 데이터베이스 서버가 동시에 여러 클라이언트의 쿼리 요청을 각각의 스레드로 처리하여 다수의 CPU 코어/스레드에 분산시켜 실행한다.
    *   **웹 서버에서 동시에 들어오는 수천 개의 요청 처리**: 각 웹 요청을 독립적인 스레드로 처리하여, 여러 CPU 코어/스레드에서 동시에 응답한다.

### 3. 데이터 수준 병렬성 (DLP: Data-Level Parallelism)

*   **정의**: 하나의 동일한 연산을 수많은 데이터 요소에 동시에 적용하는 기술이다.
*   **목적**: 대규모 데이터를 대상으로 하는 반복적인 연산의 처리 속도를 극대화하는 것이 목적이다.
*   **활용 예시**:
    *   **SIMD(Single Instruction Multiple Data) 명령어**: 하나의 명령어로 여러 데이터 요소에 대해 동일한 연산을 동시에 수행하는 CPU 명령어 확장이다.
    *   **GPU(Graphics Processing Unit)**: 수천 개의 연산 코드를 가지고 있어 그래픽 처리, 머신러닝 학습 등 동일 연산을 대규모 데이터에 병렬적으로 적용하는 데 매우 효율적인 장치이다.
*   **적용 예시**:
    *   **3D 게임 렌더링**: 수많은 픽셀과 정점에 대해 동일한 셰이딩, 텍스처링 연산을 동시에 적용한다.
    *   **머신러닝(딥러닝) 학습**: 대규모 행렬 연산과 같이 동일한 계산을 방대한 데이터에 반복적으로 적용한다.
    *   **과학 시뮬레이션**: 유체 역학 계산 등 방대한 데이터를 대상으로 하는 병렬 계산에 사용된다.
